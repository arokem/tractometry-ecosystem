{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e47a0d7",
   "metadata": {},
   "source": [
    "# How to add new bundles into pyAFQ (Optic Radiations Example)\n",
    "\n",
    "pyAFQ is designed to be customizable and extensible. This example shows how you\n",
    "can customize it to define a new bundle based on a definition of waypoint and\n",
    "endpoint ROIs of your design.\n",
    "\n",
    "In this case, we add the optic radiations, based on work by Caffara et al.\n",
    "The optic radiations (OR) are the primary projection of visual information\n",
    "from the lateral geniculate nucleus of the thalamus to the primary visual\n",
    "cortex. Studying the optic radiations with dMRI provides a linkage between white\n",
    "matter tissue properties, visual perception and behavior, and physiological\n",
    "responses of the visual cortex to visual stimulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ee655-6b82-4628-a8b5-137c2d1377cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import afq_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62590ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import plotly\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "from AFQ.api.group import GroupAFQ\n",
    "import AFQ.api.bundle_dict as abd\n",
    "import AFQ.data.fetch as afd\n",
    "from AFQ.definitions.image import ImageFile, RoiImage\n",
    "import AFQ.utils.streamlines as aus\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb726ac",
   "metadata": {},
   "source": [
    "## Get dMRI data\n",
    "\n",
    "We will analyze one subject from the Healthy Brain Network Processed Open\n",
    "Diffusion Derivatives dataset (HBN-POD2). We'll use a fetcher to\n",
    "get preprocessed dMRI data for one of the >2,000 subjects in that study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a234b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_dir = afd.fetch_hbn_preproc([\"NDARAA948VFH\"])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9cceb",
   "metadata": {},
   "source": [
    "## Define custom `BundleDict` object\n",
    "\n",
    "The `BundleDict` object holds information about \"include\" and \"exclude\" ROIs,\n",
    "as well as endpoint ROIs, and whether the bundle crosses the midline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_rois = afd.read_or_templates()\n",
    "bundles = abd.OR_bd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805baae9",
   "metadata": {},
   "source": [
    "## Define GroupAFQ object\n",
    "\n",
    "For tractography, we use CSD-based probabilistic tractography seeding\n",
    "extensively (`n_seeds=4` means 81 seeds per voxel!), but only within the ROIs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec99c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask_definition = ImageFile(\n",
    "    suffix=\"mask\",\n",
    "    filters={'desc': 'brain',\n",
    "             'space': 'T1w',\n",
    "             'scope': 'qsiprep'})\n",
    "\n",
    "my_afq = GroupAFQ(\n",
    "    bids_path=study_dir,\n",
    "    preproc_pipeline=\"qsiprep\",\n",
    "    participant_labels=[\"NDARAA948VFH\"],\n",
    "    output_dir=op.join(study_dir, \"derivatives\", \"afq_or\"),\n",
    "    brain_mask_definition=brain_mask_definition,\n",
    "    tracking_params={\"n_seeds\": 4,\n",
    "                     \"directions\": \"prob\",\n",
    "                     \"odf_model\": \"CSD\",\n",
    "                     \"seed_mask\": RoiImage()},\n",
    "    bundle_info=bundles)\n",
    "\n",
    "my_afq.export(\"profiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5bf156",
   "metadata": {},
   "source": [
    "## Visualize a montage\n",
    "\n",
    "One way to examine the output of the pyAFQ pipeline is by creating a montage\n",
    "of images of a particular bundle across a group of participants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba544dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_afq.combine_bundle(\"Left Optic Radiation\")\n",
    "montage = my_afq.group_montage(\n",
    "    \"Left Optic Radiation\",\n",
    "    (1, 1), \"Axial\", \"left\")\n",
    "Image(filename=montage[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59513f9a",
   "metadata": {},
   "source": [
    "## Interactive bundle visualization\n",
    "\n",
    "Another way to examine the outputs is to export the individual bundle\n",
    "figures, which show the streamlines, as well as the ROIs used to define the\n",
    "bundle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87252d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_html = my_afq.export(\"indiv_bundles_figures\")\n",
    "plotly.io.show(bundle_html[\"NDARAA948VFH\"][\"Left Optic Radiation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d941d",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Caffarra S, Joo SJ, Bloom D, Kruper J, Rokem A, Yeatman JD. Development\n",
    "  of the visual white matter pathways mediates development of\n",
    "  electrophysiological responses in visual cortex. Hum Brain Mapp. 2021.\n",
    "- Caffarra S, Kanopka K, Kruper J, Richie-Halford A, Roy E, Rokem A,\n",
    "  Yeatman JD. Development of the alpha rhythm is linked to visual white\n",
    "  matter pathways and visual detection performance. bioRxiv.\n",
    "- Alexander LM, Escalera J, Ai L, et al. An open resource for\n",
    "  transdiagnostic research in pediatric mental health and learning\n",
    "  disorders. Sci Data. 2017.\n",
    "- Richie-Halford A, Cieslak M, Ai L, et al. An analysis-ready and quality\n",
    "  controlled resource for pediatric brain white-matter research. Scientific\n",
    "  Data. 2022.\n",
    "- Cieslak M, Cook PA, He X, et al. QSIPrep: an integrative platform for\n",
    "  preprocessing and reconstructing diffusion MRI data. Nat Methods. 2021.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3267241-313d-4f78-9eb0-09dd25e4bdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
